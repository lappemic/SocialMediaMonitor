{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing livedata of twitter about Luzern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_url(keyword, start_time, end_time, max_results=300):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\" #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword + ' -is:retweet -is:reply',\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token=None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def response_to_df(json_response):\n",
    "    # response containes two parts : the tweets and the users\n",
    "    tweets = pd.DataFrame(json_response['data'])\n",
    "    users = pd.DataFrame(json_response['includes']['users'])\n",
    "    # enrich the tweets with the username of the author\n",
    "    id_name_dict = pd.Series(users.username.values, index=users.id).to_dict()\n",
    "    tweets['username'] = tweets.author_id.map(id_name_dict)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No twitter developer account at the moment and not further worked on it yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7fa4ad54c13063743e0b795d31fc2de87e75f8ad2886ded3b88bc7649886d47"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('socialMediaMonitor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
