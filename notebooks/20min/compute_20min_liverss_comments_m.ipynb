{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now (05.05.2022) not further processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd, numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from datetime import timedelta\n",
    "import pathlib\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute comments of aquired articles and save them to temporary csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# get the date of the moste recent article in the merged dataset\n",
    "liverss_and_coms_path = pathlib.Path.home() / 'Desktop' / 'SocialMediaMonitor' / 'data' / 'raw' / 'liverss_and_coms_20min.csv'\n",
    "liverss_and_coms_df = pd.read_csv(liverss_and_coms_path)\n",
    "liverss_and_coms_df['published'] = pd.to_datetime(liverss_and_coms_df['published'])\n",
    "most_recent_article = liverss_and_coms_df['published'].max()\n",
    "\n",
    "# get the ids of the articles that are less than 15 days old\n",
    "recent_date = pd.to_datetime(most_recent_article-timedelta(15), utc=True)\n",
    "mask = (liverss_and_coms_df['published'] > recent_date) # & (total_df['is_com_or_sub'] == 'sub')\n",
    "recent_articles = liverss_and_coms_df.loc[mask]\n",
    "recent_articles_id = recent_articles['id'].tolist()\n",
    "#print(recent_articles_id[:3])\n",
    "print(len(recent_articles_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article https://www.20min.ch/comment/811526744044 has 0 comments\n",
      "Article https://www.20min.ch/comment/897536422260 has 0 comments\n",
      "Article https://www.20min.ch/comment/402438287701 has 92 comments\n",
      "Article https://www.20min.ch/comment/709927065041 has 0 comments\n",
      "Article https://www.20min.ch/comment/139019297679 has 23 comments\n",
      "Article https://www.20min.ch/comment/126013815341 has 0 comments\n",
      "Article https://www.20min.ch/comment/543508269314 has 0 comments\n",
      "Article https://www.20min.ch/comment/270821781373 has 336 comments\n"
     ]
    }
   ],
   "source": [
    "# Configure the Chrome webdriver\n",
    "driver = webdriver.Chrome('/users/michaellappert/Downloads/chromedriver') # Needs to be adjusted client independently\n",
    "\n",
    "# get the commenents of those articles\n",
    "new_coms_df = pd.DataFrame(columns = ['author', 'published', 'summary', 'is_com_or_sub', 'link'])\n",
    "\n",
    "for article_id in recent_articles_id:\n",
    "    # print(article)\n",
    "    url = 'https://www.20min.ch/comment/'\n",
    "    comments_url = url + str(article_id)\n",
    "    # print(comments_url)\n",
    "    driver.get(comments_url)\n",
    "    \n",
    "    # scroll to load entire page (uses lazy loading)\n",
    "    check_height = driver.execute_script('return document.body.scrollHeight;')\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        height = driver.execute_script(\"return document.body.scrollHeight;\") \n",
    "        if height == check_height: \n",
    "            break \n",
    "        check_height = height\n",
    "    \n",
    "    # get authors\n",
    "    authors = driver.find_elements_by_class_name('CommentCard_authorNickname__booTY')\n",
    "    # print(authors)\n",
    "    author_list = [author.get_attribute('innerHTML') for author in authors]\n",
    "    # print(author_list)\n",
    "\n",
    "    # get publication dates\n",
    "    published_date = driver.find_elements_by_class_name('CommentCard_createdAt__LxEL2')\n",
    "    # print(published_date)\n",
    "    date_list = [pd.to_datetime(date.get_attribute('innerHTML'), format = '%d.%m.%Y, %H:%M', utc = True) for date in published_date]\n",
    "    # print(len(date_list))\n",
    "    # print(date_list)\n",
    "    \n",
    "    # get text bodys\n",
    "    bodys = driver.find_elements_by_class_name(\"CommentCard_body__KWmXR\")\n",
    "    # print(bodys)\n",
    "    body_list = [body.get_attribute('innerHTML') for body in bodys]\n",
    "    # print(body_list)\n",
    "    \n",
    "    # assesrt to make sure that we have all the data for every com\n",
    "    # may fail if the webdriver didn't wait for the page to load\n",
    "    assert len(body_list) == len(date_list) == len(author_list), \"Assertion problem, probably due to page parsing before page is fully loaded\"\n",
    "    \n",
    "    # create a temporary dataframe with the data and write it to the new_coms_df\n",
    "    temp_df = pd.DataFrame(list(zip(author_list, date_list, body_list)), columns =['author', 'published', 'summary'])\n",
    "    # print(temp_df)\n",
    "    temp_df['id'] = article_id\n",
    "    # temp_df.head()\n",
    "    temp_df['is_com_or_sub'] = 'com'\n",
    "    # print(temp_df.head())\n",
    "    # time.sleep(2)\n",
    "    temp_df['link'] = comments_url\n",
    "    # print(temp_df.head())\n",
    "    # time.sleep(2)\n",
    "    # temp_df = temp_df[temp_df['published'] > last_com_check] # -> GLOBAL VARIABLE FOR LAST_COM_CHECK MUST BE INCLUDED\n",
    "    print(f'Article {comments_url} has {len(temp_df)} comments')\n",
    "    if len(temp_df) >0:\n",
    "        new_coms_df = pd.concat([new_coms_df, temp_df], ignore_index=True, axis=0)\n",
    "\n",
    "# new_coms_df.head()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>is_com_or_sub</th>\n",
       "      <th>link</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dieti44</td>\n",
       "      <td>2022-05-08 00:15:00+00:00</td>\n",
       "      <td>Offenbar soll der gläserne Bürger mit allen mö...</td>\n",
       "      <td>com</td>\n",
       "      <td>https://www.20min.ch/comment/402438287701</td>\n",
       "      <td>4.024383e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackSabbath</td>\n",
       "      <td>2022-05-08 00:10:00+00:00</td>\n",
       "      <td>Denkt denn hier auch irgendjemand mal an die K...</td>\n",
       "      <td>com</td>\n",
       "      <td>https://www.20min.ch/comment/402438287701</td>\n",
       "      <td>4.024383e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weihnachtshase</td>\n",
       "      <td>2022-05-07 23:10:00+00:00</td>\n",
       "      <td>Wer mein Bargeld nicht will, kann es bleiben l...</td>\n",
       "      <td>com</td>\n",
       "      <td>https://www.20min.ch/comment/402438287701</td>\n",
       "      <td>4.024383e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St.Gallerli</td>\n",
       "      <td>2022-05-07 22:37:00+00:00</td>\n",
       "      <td>Bravo, tolle Entscheidung!</td>\n",
       "      <td>com</td>\n",
       "      <td>https://www.20min.ch/comment/402438287701</td>\n",
       "      <td>4.024383e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scharrukin</td>\n",
       "      <td>2022-05-07 22:27:00+00:00</td>\n",
       "      <td>Luzern ist schon lange eine Stadt die ich meid...</td>\n",
       "      <td>com</td>\n",
       "      <td>https://www.20min.ch/comment/402438287701</td>\n",
       "      <td>4.024383e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                  published  \\\n",
       "0         Dieti44  2022-05-08 00:15:00+00:00   \n",
       "1    BlackSabbath  2022-05-08 00:10:00+00:00   \n",
       "2  Weihnachtshase  2022-05-07 23:10:00+00:00   \n",
       "3     St.Gallerli  2022-05-07 22:37:00+00:00   \n",
       "4      Scharrukin  2022-05-07 22:27:00+00:00   \n",
       "\n",
       "                                             summary is_com_or_sub  \\\n",
       "0  Offenbar soll der gläserne Bürger mit allen mö...           com   \n",
       "1  Denkt denn hier auch irgendjemand mal an die K...           com   \n",
       "2  Wer mein Bargeld nicht will, kann es bleiben l...           com   \n",
       "3                        Bravo, tolle Entscheidung!            com   \n",
       "4  Luzern ist schon lange eine Stadt die ich meid...           com   \n",
       "\n",
       "                                        link            id  \n",
       "0  https://www.20min.ch/comment/402438287701  4.024383e+11  \n",
       "1  https://www.20min.ch/comment/402438287701  4.024383e+11  \n",
       "2  https://www.20min.ch/comment/402438287701  4.024383e+11  \n",
       "3  https://www.20min.ch/comment/402438287701  4.024383e+11  \n",
       "4  https://www.20min.ch/comment/402438287701  4.024383e+11  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latest coms check date\n",
    "if len(new_coms_df) > 0:\n",
    "    new_last_check_coms = new_coms_df['published'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the gotten coms to a csv file\n",
    "liverss_comments_df = new_coms_df # For this sample code, simply copy input to output\n",
    "\n",
    "\n",
    "# Saving generated data to raw data folder\n",
    "liverss_comments_df.to_csv(r'~/Desktop/SocialMediaMonitor/data/raw/liverss_comments_20Min.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c76eb199b8e1fb9fa01facb4084fceb7f49eeb0e37fb232cc5bedee7779b1e8a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
